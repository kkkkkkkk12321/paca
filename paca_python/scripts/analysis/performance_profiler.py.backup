"""
Phase 9.2: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë° ë³‘ëª©ì  í•´ê²°
PACA ì‹œìŠ¤í…œì˜ ìƒì„¸í•œ ì„±ëŠ¥ ë¶„ì„ê³¼ ìµœì í™”
"""

import asyncio
import sys
import os
import time
import json
import tracemalloc
import cProfile
import pstats
import io
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Any, Optional
import gc
import psutil

# PACA ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '.'))

from paca.tools import (
    ReActFramework, PACAToolManager, SafetyPolicy
)
from paca.tools.tools import WebSearchTool, FileManagerTool


@dataclass
class PerformanceMetric:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    operation: str
    execution_time: float
    memory_usage: float
    cpu_usage: Optional[float] = None
    success: bool = True
    error_message: Optional[str] = None
    iterations: int = 1


@dataclass
class BottleneckAnalysis:
    """ë³‘ëª©ì  ë¶„ì„ ê²°ê³¼"""
    component: str
    operation: str
    issue_type: str  # 'memory', 'cpu', 'io', 'network'
    severity: str    # 'low', 'medium', 'high', 'critical'
    impact_score: float  # 0.0 - 1.0
    recommendation: str
    estimated_improvement: str


class PerformanceProfiler:
    """PACA ì‹œìŠ¤í…œ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ëŸ¬"""

    def __init__(self):
        self.components = {}
        self.metrics = []
        self.bottlenecks = []
        self.baseline_metrics = {}

    async def setup_profiling_environment(self):
        """í”„ë¡œíŒŒì¼ë§ í™˜ê²½ ì„¤ì •"""
        print("=== ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ í™˜ê²½ ì„¤ì • ===")

        try:
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í™œì„±í™”
            gc.enable()
            gc.collect()

            # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
            tracemalloc.start()

            # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            self.components['tool_manager'] = PACAToolManager()
            self.components['web_search'] = WebSearchTool()
            self.components['file_manager'] = FileManagerTool()
            self.components['react_framework'] = ReActFramework(self.components['tool_manager'])

            # ë„êµ¬ ë“±ë¡
            self.components['tool_manager'].register_tool(self.components['web_search'])
            self.components['tool_manager'].register_tool(self.components['file_manager'])

            print("í”„ë¡œíŒŒì¼ë§ í™˜ê²½ ì„¤ì • ì™„ë£Œ")
            return True

        except Exception as e:
            print(f"í”„ë¡œíŒŒì¼ë§ í™˜ê²½ ì„¤ì • ì‹¤íŒ¨: {e}")
            return False

    async def profile_component_startup(self):
        """ì»´í¬ë„ŒíŠ¸ ì‹œì‘ ì‹œê°„ í”„ë¡œíŒŒì¼ë§"""
        print("\n=== ì»´í¬ë„ŒíŠ¸ ì‹œì‘ ì‹œê°„ í”„ë¡œíŒŒì¼ë§ ===")

        startup_metrics = []

        component_classes = [
            ('PACAToolManager', PACAToolManager),
            ('WebSearchTool', WebSearchTool),
            ('FileManagerTool', FileManagerTool)
        ]

        for name, component_class in component_classes:
            try:
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì‹œì‘
                process = psutil.Process()
                start_memory = process.memory_info().rss / 1024 / 1024  # MB

                # ì‹œì‘ ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                component = component_class()
                end_time = time.time()

                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì¢…ë£Œ
                end_memory = process.memory_info().rss / 1024 / 1024  # MB

                metric = PerformanceMetric(
                    operation=f"{name}_startup",
                    execution_time=end_time - start_time,
                    memory_usage=end_memory - start_memory,
                    success=True
                )

                startup_metrics.append(metric)
                print(f"   {name}: {metric.execution_time:.3f}ì´ˆ, {metric.memory_usage:.2f}MB")

            except Exception as e:
                metric = PerformanceMetric(
                    operation=f"{name}_startup",
                    execution_time=0,
                    memory_usage=0,
                    success=False,
                    error_message=str(e)
                )
                startup_metrics.append(metric)

        return startup_metrics

    async def profile_tool_operations(self, iterations: int = 5):
        """ë„êµ¬ ì—°ì‚° ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§"""
        print(f"\n=== ë„êµ¬ ì—°ì‚° ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ({iterations}íšŒ ë°˜ë³µ) ===")

        operation_metrics = []

        # í…ŒìŠ¤íŠ¸í•  ì—°ì‚°ë“¤
        operations = [
            {
                'name': 'web_search_small',
                'tool': 'web_search',
                'params': {'query': 'Python'}
            },
            {
                'name': 'web_search_medium',
                'tool': 'web_search',
                'params': {'query': 'Python programming language features'}
            },
            {
                'name': 'file_write_small',
                'tool': 'file_manager',
                'params': {'operation': 'write', 'path': 'test_small.txt', 'content': 'small content'}
            },
            {
                'name': 'file_write_large',
                'tool': 'file_manager',
                'params': {'operation': 'write', 'path': 'test_large.txt', 'content': 'large content ' * 1000}
            },
            {
                'name': 'file_read_operations',
                'tool': 'file_manager',
                'params': {'operation': 'read', 'path': 'test_small.txt'}
            }
        ]

        for operation in operations:
            print(f"   í…ŒìŠ¤íŠ¸ ì¤‘: {operation['name']}")

            execution_times = []
            memory_usages = []
            success_count = 0

            for i in range(iterations):
                try:
                    # ë©”ëª¨ë¦¬ ì¸¡ì • ì‹œì‘
                    process = psutil.Process()
                    start_memory = process.memory_info().rss / 1024 / 1024

                    # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
                    start_time = time.time()
                    result = await self.components['tool_manager'].execute_tool(
                        operation['tool'],
                        **operation['params']
                    )
                    end_time = time.time()

                    # ë©”ëª¨ë¦¬ ì¸¡ì • ì¢…ë£Œ
                    end_memory = process.memory_info().rss / 1024 / 1024

                    execution_times.append(end_time - start_time)
                    memory_usages.append(end_memory - start_memory)

                    if result.success:
                        success_count += 1

                    # ë©”ëª¨ë¦¬ ì •ë¦¬
                    gc.collect()

                except Exception as e:
                    print(f"      ë°˜ë³µ {i+1} ì‹¤íŒ¨: {e}")

            # í†µê³„ ê³„ì‚°
            if execution_times:
                avg_time = sum(execution_times) / len(execution_times)
                avg_memory = sum(memory_usages) / len(memory_usages)
                success_rate = success_count / iterations

                metric = PerformanceMetric(
                    operation=operation['name'],
                    execution_time=avg_time,
                    memory_usage=avg_memory,
                    success=success_rate > 0.8,
                    iterations=iterations
                )

                operation_metrics.append(metric)
                print(f"      í‰ê·  ì‹œê°„: {avg_time:.3f}ì´ˆ, í‰ê·  ë©”ëª¨ë¦¬: {avg_memory:.2f}MB, ì„±ê³µë¥ : {success_rate:.1%}")

        return operation_metrics

    async def profile_react_framework(self):
        """ReAct í”„ë ˆì„ì›Œí¬ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§"""
        print("\n=== ReAct í”„ë ˆì„ì›Œí¬ ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ===")

        react_metrics = []

        try:
            # ì„¸ì…˜ ìƒì„± í”„ë¡œíŒŒì¼ë§
            start_time = time.time()
            session = await self.components['react_framework'].create_session(
                goal="ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì„¸ì…˜",
                max_steps=10
            )
            session_time = time.time() - start_time

            react_metrics.append(PerformanceMetric(
                operation="react_session_creation",
                execution_time=session_time,
                memory_usage=0,  # ì¶”í›„ ìƒì„¸ ì¸¡ì • ê°€ëŠ¥
                success=True
            ))

            # ë‹¨ê³„ë³„ ì—°ì‚° í”„ë¡œíŒŒì¼ë§
            steps = [
                ('think', "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìƒê°"),
                ('act_web_search', {'tool': 'web_search', 'query': 'performance test'}),
                ('observe', "ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê´€ì°°í–ˆìŠµë‹ˆë‹¤"),
                ('act_file_write', {'tool': 'file_manager', 'operation': 'write', 'path': 'react_test.txt', 'content': 'test'}),
                ('reflect', "íŒŒì¼ ì‘ì„±ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤")
            ]

            for step_name, step_data in steps:
                start_time = time.time()

                if step_name == 'think':
                    await self.components['react_framework'].think(session, step_data)
                elif step_name.startswith('act_'):
                    tool_name = step_data['tool']
                    params = {k: v for k, v in step_data.items() if k != 'tool'}
                    await self.components['react_framework'].act(session, tool_name, **params)
                elif step_name == 'observe':
                    await self.components['react_framework'].observe(session, step_data)
                elif step_name == 'reflect':
                    await self.components['react_framework'].reflect(session, step_data)

                step_time = time.time() - start_time

                react_metrics.append(PerformanceMetric(
                    operation=f"react_{step_name}",
                    execution_time=step_time,
                    memory_usage=0,
                    success=True
                ))

                print(f"   {step_name}: {step_time:.3f}ì´ˆ")

        except Exception as e:
            react_metrics.append(PerformanceMetric(
                operation="react_framework_error",
                execution_time=0,
                memory_usage=0,
                success=False,
                error_message=str(e)
            ))

        return react_metrics

    async def profile_memory_usage(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìƒì„¸ í”„ë¡œíŒŒì¼ë§"""
        print("\n=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í”„ë¡œíŒŒì¼ë§ ===")

        memory_metrics = []

        try:
            # í˜„ì¬ ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ·
            current, peak = tracemalloc.get_traced_memory()

            # ëŒ€ìš©ëŸ‰ ì‘ì—… ìˆ˜í–‰
            large_operations = [
                {'name': 'large_web_search', 'iterations': 10},
                {'name': 'multiple_file_operations', 'iterations': 50},
                {'name': 'react_sessions', 'iterations': 5}
            ]

            for operation in large_operations:
                gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                start_current, start_peak = tracemalloc.get_traced_memory()

                if operation['name'] == 'large_web_search':
                    for i in range(operation['iterations']):
                        await self.components['tool_manager'].execute_tool(
                            'web_search',
                            query=f'test query number {i}'
                        )

                elif operation['name'] == 'multiple_file_operations':
                    for i in range(operation['iterations']):
                        await self.components['tool_manager'].execute_tool(
                            'file_manager',
                            operation='write',
                            path=f'memory_test_{i}.txt',
                            content=f'content {i} ' * 100
                        )

                elif operation['name'] == 'react_sessions':
                    for i in range(operation['iterations']):
                        session = await self.components['react_framework'].create_session(
                            goal=f"ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ {i}",
                            max_steps=3
                        )

                end_current, end_peak = tracemalloc.get_traced_memory()

                memory_metric = PerformanceMetric(
                    operation=operation['name'],
                    execution_time=0,  # ë©”ëª¨ë¦¬ ì¸¡ì •ì´ë¯€ë¡œ ì‹œê°„ì€ 0
                    memory_usage=(end_current - start_current) / 1024 / 1024,  # MB
                    success=True,
                    iterations=operation['iterations']
                )

                memory_metrics.append(memory_metric)
                print(f"   {operation['name']}: {memory_metric.memory_usage:.2f}MB ì¦ê°€")

        except Exception as e:
            print(f"ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì˜¤ë¥˜: {e}")

        return memory_metrics

    def analyze_bottlenecks(self, all_metrics: List[PerformanceMetric]) -> List[BottleneckAnalysis]:
        """ë³‘ëª©ì  ë¶„ì„"""
        print("\n=== ë³‘ëª©ì  ë¶„ì„ ===")

        bottlenecks = []

        # ì‹¤í–‰ ì‹œê°„ ê¸°ë°˜ ë³‘ëª©ì  ì‹ë³„
        time_threshold = 1.0  # 1ì´ˆ
        memory_threshold = 50.0  # 50MB

        for metric in all_metrics:
            if not metric.success:
                bottlenecks.append(BottleneckAnalysis(
                    component=metric.operation.split('_')[0],
                    operation=metric.operation,
                    issue_type='error',
                    severity='critical',
                    impact_score=1.0,
                    recommendation=f"ì˜¤ë¥˜ í•´ê²° í•„ìš”: {metric.error_message}",
                    estimated_improvement="ì˜¤ë¥˜ í•´ê²°ì‹œ 100% ê°œì„ "
                ))

            if metric.execution_time > time_threshold:
                severity = 'high' if metric.execution_time > 3.0 else 'medium'
                impact_score = min(metric.execution_time / 5.0, 1.0)

                bottlenecks.append(BottleneckAnalysis(
                    component=metric.operation.split('_')[0],
                    operation=metric.operation,
                    issue_type='cpu',
                    severity=severity,
                    impact_score=impact_score,
                    recommendation="ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”, ìºì‹± ë„ì… ê²€í† ",
                    estimated_improvement=f"{min(50, int(impact_score * 100))}% ê°œì„  ê°€ëŠ¥"
                ))

            if metric.memory_usage > memory_threshold:
                severity = 'high' if metric.memory_usage > 100.0 else 'medium'
                impact_score = min(metric.memory_usage / 200.0, 1.0)

                bottlenecks.append(BottleneckAnalysis(
                    component=metric.operation.split('_')[0],
                    operation=metric.operation,
                    issue_type='memory',
                    severity=severity,
                    impact_score=impact_score,
                    recommendation="ë©”ëª¨ë¦¬ í’€ë§, ê°ì²´ ì¬ì‚¬ìš©, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”",
                    estimated_improvement=f"{min(40, int(impact_score * 80))}% ë©”ëª¨ë¦¬ ì ˆì•½ ê°€ëŠ¥"
                ))

        # ë³‘ëª©ì  ìš°ì„ ìˆœìœ„ ì •ë ¬
        bottlenecks.sort(key=lambda x: (
            {'critical': 4, 'high': 3, 'medium': 2, 'low': 1}[x.severity],
            x.impact_score
        ), reverse=True)

        if bottlenecks:
            print(f"   ë°œê²¬ëœ ë³‘ëª©ì : {len(bottlenecks)}ê°œ")
            for i, bottleneck in enumerate(bottlenecks[:5], 1):  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
                print(f"   {i}. [{bottleneck.severity.upper()}] {bottleneck.operation}")
                print(f"      íƒ€ì…: {bottleneck.issue_type}, ì˜í–¥ë„: {bottleneck.impact_score:.2f}")
                print(f"      ê¶Œì¥ì‚¬í•­: {bottleneck.recommendation}")
        else:
            print("   ë³‘ëª©ì ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return bottlenecks

    def generate_optimization_plan(self, bottlenecks: List[BottleneckAnalysis]) -> Dict[str, Any]:
        """ìµœì í™” ê³„íš ìƒì„±"""
        print("\n=== ìµœì í™” ê³„íš ìƒì„± ===")

        optimization_plan = {
            'immediate_actions': [],  # ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­
            'short_term_improvements': [],  # ë‹¨ê¸° ê°œì„ ì‚¬í•­
            'long_term_strategies': [],  # ì¥ê¸° ì „ëµ
            'estimated_benefits': {}
        }

        # ì‹¬ê°ë„ë³„ ë¶„ë¥˜
        critical_issues = [b for b in bottlenecks if b.severity == 'critical']
        high_issues = [b for b in bottlenecks if b.severity == 'high']
        medium_issues = [b for b in bottlenecks if b.severity == 'medium']

        # ì¦‰ì‹œ ì¡°ì¹˜ ì‚¬í•­ (critical)
        for issue in critical_issues:
            optimization_plan['immediate_actions'].append({
                'issue': issue.operation,
                'action': issue.recommendation,
                'priority': 'critical',
                'estimated_effort': 'high'
            })

        # ë‹¨ê¸° ê°œì„ ì‚¬í•­ (high)
        for issue in high_issues:
            if issue.issue_type == 'memory':
                optimization_plan['short_term_improvements'].append({
                    'area': 'memory_optimization',
                    'actions': ['ë©”ëª¨ë¦¬ í’€ êµ¬í˜„', 'ê°ì²´ ì¬ì‚¬ìš© íŒ¨í„´ ë„ì…', 'ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŠœë‹'],
                    'estimated_benefit': issue.estimated_improvement
                })
            elif issue.issue_type == 'cpu':
                optimization_plan['short_term_improvements'].append({
                    'area': 'performance_optimization',
                    'actions': ['ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„ ', 'ìºì‹± ë ˆì´ì–´ ì¶”ê°€', 'ë°°ì¹˜ ì²˜ë¦¬ ë„ì…'],
                    'estimated_benefit': issue.estimated_improvement
                })

        # ì¥ê¸° ì „ëµ (medium + ì „ì²´ì  ê°œì„ )
        if medium_issues:
            optimization_plan['long_term_strategies'].extend([
                'ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•',
                'ìë™ ìµœì í™” ë©”ì»¤ë‹ˆì¦˜ ë„ì…',
                'ë¶„ì‚° ì²˜ë¦¬ ì•„í‚¤í…ì²˜ ê²€í† ',
                'AI ê¸°ë°˜ ìì› ê´€ë¦¬ ì‹œìŠ¤í…œ ê°œë°œ'
            ])

        # ì˜ˆìƒ íš¨ê³¼ ê³„ì‚°
        total_time_improvement = sum(
            float(b.estimated_improvement.replace('%', '').replace(' ê°œì„  ê°€ëŠ¥', '').replace(' ë©”ëª¨ë¦¬ ì ˆì•½ ê°€ëŠ¥', ''))
            for b in bottlenecks[:3]  # ìƒìœ„ 3ê°œ
            if 'ê°œì„ ' in b.estimated_improvement and '%' in b.estimated_improvement
        ) / 3

        optimization_plan['estimated_benefits'] = {
            'performance_improvement': f"{total_time_improvement:.1f}%",
            'memory_savings': "20-40%",
            'stability_increase': "95%+",
            'maintenance_reduction': "30%"
        }

        return optimization_plan

    async def generate_performance_report(self):
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        print("\n=== ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„± ===")

        # ëª¨ë“  í”„ë¡œíŒŒì¼ë§ ì‹¤í–‰
        startup_metrics = await self.profile_component_startup()
        operation_metrics = await self.profile_tool_operations()
        react_metrics = await self.profile_react_framework()
        memory_metrics = await self.profile_memory_usage()

        all_metrics = startup_metrics + operation_metrics + react_metrics + memory_metrics

        # ë³‘ëª©ì  ë¶„ì„
        bottlenecks = self.analyze_bottlenecks(all_metrics)

        # ìµœì í™” ê³„íš ìƒì„±
        optimization_plan = self.generate_optimization_plan(bottlenecks)

        # ë³´ê³ ì„œ ì‘ì„±
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'phase': 'Phase 9.2 - ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë° ë³‘ëª©ì  í•´ê²°',
            'profiling_summary': {
                'total_operations_tested': len(all_metrics),
                'successful_operations': len([m for m in all_metrics if m.success]),
                'failed_operations': len([m for m in all_metrics if not m.success]),
                'average_execution_time': sum(m.execution_time for m in all_metrics if m.success) / len([m for m in all_metrics if m.success]) if all_metrics else 0,
                'total_memory_usage': sum(m.memory_usage for m in all_metrics if m.success),
                'bottlenecks_found': len(bottlenecks)
            },
            'detailed_metrics': {
                'startup_metrics': [
                    {
                        'operation': m.operation,
                        'execution_time': m.execution_time,
                        'memory_usage': m.memory_usage,
                        'success': m.success
                    } for m in startup_metrics
                ],
                'operation_metrics': [
                    {
                        'operation': m.operation,
                        'execution_time': m.execution_time,
                        'memory_usage': m.memory_usage,
                        'success': m.success,
                        'iterations': m.iterations
                    } for m in operation_metrics
                ],
                'react_metrics': [
                    {
                        'operation': m.operation,
                        'execution_time': m.execution_time,
                        'success': m.success
                    } for m in react_metrics
                ],
                'memory_metrics': [
                    {
                        'operation': m.operation,
                        'memory_usage': m.memory_usage,
                        'iterations': m.iterations
                    } for m in memory_metrics
                ]
            },
            'bottleneck_analysis': [
                {
                    'component': b.component,
                    'operation': b.operation,
                    'issue_type': b.issue_type,
                    'severity': b.severity,
                    'impact_score': b.impact_score,
                    'recommendation': b.recommendation,
                    'estimated_improvement': b.estimated_improvement
                } for b in bottlenecks
            ],
            'optimization_plan': optimization_plan,
            'next_phase_readiness': 'ready' if len([b for b in bottlenecks if b.severity == 'critical']) == 0 else 'needs_fixes'
        }

        return report


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("PACA Phase 9.2: ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë° ë³‘ëª©ì  í•´ê²°")
    print("=" * 60)

    profiler = PerformanceProfiler()

    try:
        # 1. í”„ë¡œíŒŒì¼ë§ í™˜ê²½ ì„¤ì •
        if not await profiler.setup_profiling_environment():
            print("í”„ë¡œíŒŒì¼ë§ í™˜ê²½ ì„¤ì • ì‹¤íŒ¨")
            return False

        # 2. ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±
        report = await profiler.generate_performance_report()

        # 3. ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ìš”ì•½:")
        print(f"   â€¢ í…ŒìŠ¤íŠ¸í•œ ì—°ì‚°: {report['profiling_summary']['total_operations_tested']}ê°œ")
        print(f"   â€¢ ì„±ê³µí•œ ì—°ì‚°: {report['profiling_summary']['successful_operations']}ê°œ")
        print(f"   â€¢ ì‹¤íŒ¨í•œ ì—°ì‚°: {report['profiling_summary']['failed_operations']}ê°œ")
        print(f"   â€¢ í‰ê·  ì‹¤í–‰ ì‹œê°„: {report['profiling_summary']['average_execution_time']:.3f}ì´ˆ")
        print(f"   â€¢ ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {report['profiling_summary']['total_memory_usage']:.2f}MB")
        print(f"   â€¢ ë°œê²¬ëœ ë³‘ëª©ì : {report['profiling_summary']['bottlenecks_found']}ê°œ")

        if report['bottleneck_analysis']:
            print(f"\nğŸ” ì£¼ìš” ë³‘ëª©ì :")
            for i, bottleneck in enumerate(report['bottleneck_analysis'][:3], 1):
                print(f"   {i}. [{bottleneck['severity'].upper()}] {bottleneck['operation']}")
                print(f"      â€¢ íƒ€ì…: {bottleneck['issue_type']}")
                print(f"      â€¢ ì˜í–¥ë„: {bottleneck['impact_score']:.2f}")
                print(f"      â€¢ ê¶Œì¥ì‚¬í•­: {bottleneck['recommendation']}")

        if report['optimization_plan']['estimated_benefits']:
            print(f"\nğŸ¯ ì˜ˆìƒ ìµœì í™” íš¨ê³¼:")
            benefits = report['optimization_plan']['estimated_benefits']
            print(f"   â€¢ ì„±ëŠ¥ ê°œì„ : {benefits.get('performance_improvement', 'N/A')}")
            print(f"   â€¢ ë©”ëª¨ë¦¬ ì ˆì•½: {benefits.get('memory_savings', 'N/A')}")
            print(f"   â€¢ ì•ˆì •ì„± í–¥ìƒ: {benefits.get('stability_increase', 'N/A')}")

        print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„ ìƒíƒœ: {report['next_phase_readiness']}")

        # 4. ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_file = "performance_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ! ìƒì„¸ ë³´ê³ ì„œ: {report_file}")
        return True

    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # ë©”ëª¨ë¦¬ ì¶”ì  ì •ë¦¬
        try:
            tracemalloc.stop()
        except:
            pass


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)