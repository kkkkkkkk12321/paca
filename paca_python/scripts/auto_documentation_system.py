"""
Automatic README.md Generation System for PACA Python Conversion
ìë™ README.md ìƒì„± ì‹œìŠ¤í…œ - 9ê°œ ì„¹ì…˜ í‘œì¤€ ì¤€ìˆ˜

This system automatically generates comprehensive README.md files with 9 required sections
for every module during the TypeScript to Python conversion process.
"""

import os
import ast
import re
import json
from pathlib import Path
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass
from datetime import datetime


@dataclass
class CodeAnalysis:
    """ì½”ë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    classes: List[Dict[str, Any]]
    functions: List[Dict[str, Any]]
    dependencies: List[str]
    apis: List[Dict[str, Any]]
    tests: List[str]
    performance_notes: List[str]
    file_count: int
    line_count: int
    complexity_score: float


class CodeAnalyzer:
    """Python ì½”ë“œ ì •ì  ë¶„ì„ìœ¼ë¡œ ë¬¸ì„œí™” ì •ë³´ ì¶”ì¶œ"""

    def __init__(self):
        self.performance_patterns = [
            "async def", "await", "asyncio", "concurrent.futures",
            "multiprocessing", "threading", "cache", "lru_cache"
        ]

    def analyze_module(self, module_path: str) -> CodeAnalysis:
        """ëª¨ë“ˆ ì „ì²´ ë¶„ì„"""
        path = Path(module_path)
        if not path.exists():
            return self._empty_analysis()

        analysis = CodeAnalysis(
            classes=[],
            functions=[],
            dependencies=[],
            apis=[],
            tests=[],
            performance_notes=[],
            file_count=0,
            line_count=0,
            complexity_score=0.0
        )

        # Python íŒŒì¼ë“¤ ì°¾ê¸°
        python_files = list(path.rglob("*.py"))
        analysis.file_count = len(python_files)

        for py_file in python_files:
            self._analyze_file(py_file, analysis)

        # ë³µì¡ë„ ê³„ì‚°
        analysis.complexity_score = self._calculate_complexity(analysis)

        return analysis

    def _analyze_file(self, file_path: Path, analysis: CodeAnalysis):
        """ê°œë³„ íŒŒì¼ ë¶„ì„"""
        try:
            content = file_path.read_text(encoding='utf-8')
            analysis.line_count += len(content.splitlines())

            # AST íŒŒì‹±
            tree = ast.parse(content)

            # í´ë˜ìŠ¤ ì¶”ì¶œ
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    analysis.classes.append({
                        'name': node.name,
                        'docstring': ast.get_docstring(node),
                        'methods': [n.name for n in node.body if isinstance(n, ast.FunctionDef)],
                        'file': str(file_path)
                    })
                elif isinstance(node, ast.FunctionDef):
                    analysis.functions.append({
                        'name': node.name,
                        'docstring': ast.get_docstring(node),
                        'args': [arg.arg for arg in node.args.args],
                        'file': str(file_path),
                        'is_async': isinstance(node, ast.AsyncFunctionDef)
                    })
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    self._extract_imports(node, analysis)

            # ì„±ëŠ¥ íŒ¨í„´ ì°¾ê¸°
            for pattern in self.performance_patterns:
                if pattern in content:
                    analysis.performance_notes.append(f"{pattern} found in {file_path.name}")

            # API íŒ¨í„´ ì°¾ê¸° (FastAPI, Flask ë“±)
            if any(framework in content for framework in ['@app.', '@router.', 'fastapi', 'flask']):
                api_routes = re.findall(r'@\w+\.(get|post|put|delete|patch)\((["\'])([^"\']+)\2\)', content)
                for method, _, route in api_routes:
                    analysis.apis.append({
                        'method': method.upper(),
                        'route': route,
                        'file': str(file_path)
                    })

            # í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸
            if 'test_' in file_path.name or '_test.py' in file_path.name:
                analysis.tests.append(str(file_path))

        except Exception as e:
            print(f"Error analyzing {file_path}: {e}")

    def _extract_imports(self, node: ast.AST, analysis: CodeAnalysis):
        """import ë¬¸ì—ì„œ ì˜ì¡´ì„± ì¶”ì¶œ"""
        if isinstance(node, ast.Import):
            for alias in node.names:
                analysis.dependencies.append(alias.name)
        elif isinstance(node, ast.ImportFrom):
            if node.module:
                analysis.dependencies.append(node.module)

    def _calculate_complexity(self, analysis: CodeAnalysis) -> float:
        """ë³µì¡ë„ ì ìˆ˜ ê³„ì‚° (0.0 - 1.0)"""
        base_score = 0.0

        # íŒŒì¼ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ë„
        if analysis.file_count > 10:
            base_score += 0.3
        elif analysis.file_count > 5:
            base_score += 0.2
        else:
            base_score += 0.1

        # í´ë˜ìŠ¤/í•¨ìˆ˜ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ë„
        total_components = len(analysis.classes) + len(analysis.functions)
        if total_components > 50:
            base_score += 0.3
        elif total_components > 20:
            base_score += 0.2
        else:
            base_score += 0.1

        # ì˜ì¡´ì„±ì— ë”°ë¥¸ ë³µì¡ë„
        unique_deps = len(set(analysis.dependencies))
        if unique_deps > 15:
            base_score += 0.3
        elif unique_deps > 8:
            base_score += 0.2
        else:
            base_score += 0.1

        # APIê°€ ìˆìœ¼ë©´ ë³µì¡ë„ ì¦ê°€
        if analysis.apis:
            base_score += 0.1

        return min(base_score, 1.0)

    def _empty_analysis(self) -> CodeAnalysis:
        """ë¹ˆ ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return CodeAnalysis([], [], [], [], [], [], 0, 0, 0.0)


class AutoDocumentationGenerator:
    """
    ëª¨ë“  í´ë”ì— 9ê°œ ì„¹ì…˜ README.md ìë™ ìƒì„±
    ì½”ë“œ ë¶„ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì¶”ì¶œ
    """

    def __init__(self):
        self.section_templates = self._load_templates()
        self.code_analyzer = CodeAnalyzer()

    def generate_module_readme(self, module_path: str, module_name: str = None) -> str:
        """ëª¨ë“ˆ ë¶„ì„ í›„ 9ê°œ ì„¹ì…˜ ì™„ì „í•œ README.md ìƒì„±"""
        path = Path(module_path)
        analysis = self.code_analyzer.analyze_module(module_path)

        if not module_name:
            module_name = path.name.replace('_', ' ').title()

        readme_content = {
            "project_overview": self._generate_overview(module_name, analysis),
            "folder_structure": self._generate_structure(path, analysis),
            "functional_requirements": self._generate_requirements(analysis),
            "technical_requirements": self._generate_tech_specs(analysis),
            "routing_entrypoints": self._generate_entrypoints(analysis),
            "code_quality_guide": self._generate_quality_guide(analysis),
            "execution_methods": self._generate_execution_guide(module_name, analysis),
            "testing_methods": self._generate_test_guide(analysis),
            "additional_considerations": self._generate_considerations(analysis)
        }

        formatted_readme = self._format_readme(readme_content, module_name)

        # README.md íŒŒì¼ ìƒì„±
        readme_path = path / "README.md"
        readme_path.write_text(formatted_readme, encoding='utf-8')

        return formatted_readme

    def _generate_overview(self, module_name: str, analysis: CodeAnalysis) -> str:
        """í”„ë¡œì íŠ¸ ê°œìš” ì„¹ì…˜ ìƒì„±"""
        purpose_map = {
            'core': 'PACA ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ë°˜ ëª¨ë“ˆë¡œ, íƒ€ì… ì •ì˜, ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ, ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹',
            'cognitive': 'ì¸ì§€ ëª¨ë¸(ACT-R, SOAR)ê³¼ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì—¬ ì¸ê°„ê³¼ ìœ ì‚¬í•œ ì‚¬ê³  ê³¼ì •ì„ ëª¨ë¸ë§',
            'learning': 'ììœ¨í•™ìŠµ ì—”ì§„ê³¼ í•œêµ­ì–´ ìµœì í™”ëœ í•™ìŠµ íŒ¨í„´ì„ í†µí•´ ì§€ì†ì ì¸ ì„±ëŠ¥ í–¥ìƒì„ ì œê³µ',
            'reasoning': 'ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ë©”íƒ€ì¸ì§€ ì‹œìŠ¤í…œì„ í†µí•´ ë³µì¡í•œ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ êµ¬í˜„',
            'mathematics': 'ìˆ˜í•™ì  ì—°ì‚°ê³¼ ì¦ëª… ì‹œìŠ¤í…œì„ ì œê³µí•˜ì—¬ ì •í™•í•œ ê³„ì‚°ê³¼ ë…¼ë¦¬ì  ì¶”ë¡ ì„ ì§€ì›',
            'services': 'PACAì˜ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ ì„œë¹„ìŠ¤ ë ˆì´ì–´ë¥¼ êµ¬í˜„í•˜ì—¬ ëª¨ë“ˆ ê°„ í†µì‹ ì„ ê´€ë¦¬',
            'integrations': 'ì™¸ë¶€ API(Google AI, KoNLPy)ì™€ì˜ í†µí•©ì„ ë‹´ë‹¹í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•œ AI ê¸°ëŠ¥ì„ ì œê³µ',
            'data': 'SQLite ê¸°ë°˜ ë°ì´í„° ì €ì¥ì†Œì™€ ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ë°ì´í„° ì˜ì†ì„±ì„ ë³´ì¥',
            'config': 'í™˜ê²½ ì„¤ì •ê³¼ êµ¬ì„± ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ì—¬ ê°œë°œ/ìš´ì˜ í™˜ê²½ë³„ ìœ ì—°í•œ ì„¤ì •ì„ ì œê³µ'
        }

        module_key = module_name.lower().replace(' ', '_')
        purpose = purpose_map.get(module_key, f'{module_name} ëª¨ë“ˆì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ë‹´ë‹¹')

        return f"{purpose}. ({analysis.file_count}ê°œ íŒŒì¼, {analysis.line_count}ì¤„)"

    def _generate_structure(self, path: Path, analysis: CodeAnalysis) -> str:
        """í´ë”/íŒŒì¼ êµ¬ì¡° ì„¹ì…˜ ìƒì„±"""
        structure = f"{path.name}/\n"

        # ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ìƒì„±
        try:
            for item in sorted(path.iterdir()):
                if item.name.startswith('.'):
                    continue

                if item.is_file():
                    if item.suffix == '.py':
                        # Python íŒŒì¼ì— ëŒ€í•œ ì„¤ëª… ì¶”ê°€
                        description = self._get_file_description(item, analysis)
                        structure += f"â”œâ”€â”€ {item.name:<20} # {description}\n"
                    else:
                        structure += f"â”œâ”€â”€ {item.name}\n"
                elif item.is_dir():
                    structure += f"â”œâ”€â”€ {item.name}/\n"
                    # í•˜ìœ„ ë””ë ‰í† ë¦¬ì˜ ì£¼ìš” íŒŒì¼ë“¤ë„ í‘œì‹œ (ìµœëŒ€ 3ê°œ)
                    sub_files = [f for f in item.iterdir() if f.is_file() and f.suffix == '.py'][:3]
                    for sub_file in sub_files:
                        structure += f"â”‚   â”œâ”€â”€ {sub_file.name}\n"
                    if len(list(item.glob('*.py'))) > 3:
                        structure += f"â”‚   â””â”€â”€ ... (ë” ë§ì€ íŒŒì¼ë“¤)\n"
        except PermissionError:
            structure += "â”œâ”€â”€ (ì ‘ê·¼ ê¶Œí•œ í•„ìš”)\n"

        structure += "â””â”€â”€ README.md           # ì´ ë¬¸ì„œ\n"
        return structure

    def _get_file_description(self, file_path: Path, analysis: CodeAnalysis) -> str:
        """íŒŒì¼ë³„ ì„¤ëª… ìƒì„±"""
        descriptions = {
            '__init__.py': 'ëª¨ë“ˆ ì§„ì…ì  ë° ê³µê°œ API ì •ì˜',
            'types.py': 'íƒ€ì… ì •ì˜ ë° ë°ì´í„° í´ë˜ìŠ¤',
            'events.py': 'ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ë° EventBus',
            'errors.py': 'ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ë“¤',
            'utils.py': 'ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤',
            'constants.py': 'ì‹œìŠ¤í…œ ìƒìˆ˜ ë° ì„¤ì •ê°’',
            'base.py': 'ê¸°ë³¸ í´ë˜ìŠ¤ ë° ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤',
            'engine.py': 'í•µì‹¬ ì—”ì§„ ë° ì²˜ë¦¬ ë¡œì§',
            'models.py': 'ë°ì´í„° ëª¨ë¸ ë° ìŠ¤í‚¤ë§ˆ',
            'config.py': 'ì„¤ì • ê´€ë¦¬ ë° í™˜ê²½ ë³€ìˆ˜'
        }

        filename = file_path.name
        if filename in descriptions:
            return descriptions[filename]

        # íŒŒì¼ ë‚´ìš© ê¸°ë°˜ ì„¤ëª… ìƒì„±
        for cls in analysis.classes:
            if file_path.name in cls['file']:
                return f"{cls['name']} í´ë˜ìŠ¤ êµ¬í˜„"

        for func in analysis.functions:
            if file_path.name in func['file'] and not func['name'].startswith('_'):
                return f"{func['name']} ê´€ë ¨ ê¸°ëŠ¥"

        return "ëª¨ë“ˆ êµ¬ì„± ìš”ì†Œ"

    def _generate_requirements(self, analysis: CodeAnalysis) -> str:
        """ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ ì„¹ì…˜ ìƒì„±"""
        reqs = "**ì…ë ¥**: "
        if analysis.classes:
            main_classes = [cls['name'] for cls in analysis.classes[:3]]
            reqs += f"{', '.join(main_classes)} ë“±ì˜ ê°ì²´\n"
        else:
            reqs += "ëª¨ë“ˆ ì´ˆê¸°í™” ë° ì„¤ì • ë°ì´í„°\n"

        reqs += "**ì¶œë ¥**: "
        if analysis.apis:
            reqs += f"API ì‘ë‹µ ({len(analysis.apis)}ê°œ ì—”ë“œí¬ì¸íŠ¸)\n"
        elif analysis.functions:
            reqs += f"ì²˜ë¦¬ëœ ê²°ê³¼ ê°ì²´ ë° ìƒíƒœ ì •ë³´\n"
        else:
            reqs += "ëª¨ë“ˆ ì²˜ë¦¬ ê²°ê³¼ ë° ìƒíƒœ\n"

        reqs += "**í•µì‹¬ ë¡œì§**: "
        if analysis.performance_notes:
            reqs += "ë¹„ë™ê¸° ì²˜ë¦¬ â†’ "
        reqs += "ì…ë ¥ ê²€ì¦ â†’ ë°ì´í„° ì²˜ë¦¬ â†’ ê²°ê³¼ ë°˜í™˜ â†’ ì—ëŸ¬ ì²˜ë¦¬"

        return reqs

    def _generate_tech_specs(self, analysis: CodeAnalysis) -> str:
        """ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ ì„¹ì…˜ ìƒì„±"""
        specs = "- Python 3.9+\n"

        # ì£¼ìš” ì˜ì¡´ì„± ì°¾ê¸°
        important_deps = []
        external_deps = ['asyncio', 'pydantic', 'numpy', 'pandas', 'aiofiles',
                        'customtkinter', 'konlpy', 'transformers', 'google']

        for dep in analysis.dependencies:
            for ext_dep in external_deps:
                if ext_dep in dep.lower():
                    important_deps.append(ext_dep)
                    break

        if important_deps:
            specs += f"- ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬: {', '.join(set(important_deps))}\n"

        # ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ ì¶”ì •
        if analysis.file_count > 20:
            specs += "- ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­: < 500MB\n"
        elif analysis.file_count > 10:
            specs += "- ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­: < 200MB\n"
        else:
            specs += "- ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­: < 100MB\n"

        # ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
        if analysis.performance_notes:
            specs += "- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì› (asyncio)\n"

        if analysis.apis:
            specs += "- API ì‘ë‹µì‹œê°„: < 200ms\n"

        return specs

    def _generate_entrypoints(self, analysis: CodeAnalysis) -> str:
        """ë¼ìš°íŒ… ë° ì§„ì…ì  ì„¹ì…˜ ìƒì„±"""
        entry = ""

        # API ë¼ìš°íŠ¸ê°€ ìˆëŠ” ê²½ìš°
        if analysis.apis:
            entry += "**API ì—”ë“œí¬ì¸íŠ¸**:\n"
            for api in analysis.apis[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                entry += f"- {api['method']} {api['route']}\n"
            if len(analysis.apis) > 5:
                entry += f"- ... ({len(analysis.apis) - 5}ê°œ ë”)\n"
            entry += "\n"

        # ì£¼ìš” í´ë˜ìŠ¤ ì§„ì…ì 
        if analysis.classes:
            entry += "**ì£¼ìš” í´ë˜ìŠ¤**:\n```python\n"
            for cls in analysis.classes[:3]:
                module_path = Path(cls['file']).stem
                entry += f"from paca.{module_path} import {cls['name']}\n"
            entry += "```\n\n"

        # ì£¼ìš” í•¨ìˆ˜ ì§„ì…ì 
        public_functions = [f for f in analysis.functions if not f['name'].startswith('_')][:3]
        if public_functions:
            entry += "**ì£¼ìš” í•¨ìˆ˜**:\n```python\n"
            for func in public_functions:
                args_str = ', '.join(func['args'])
                entry += f"{func['name']}({args_str})\n"
            entry += "```"

        return entry or "**ëª¨ë“ˆ import**:\n```python\nimport paca.module_name\n```"

    def _generate_quality_guide(self, analysis: CodeAnalysis) -> str:
        """ì½”ë“œ í’ˆì§ˆ ê°€ì´ë“œ ì„¹ì…˜ ìƒì„±"""
        guide = "**ì½”ë”© ê·œì¹™**:\n"
        guide += "- í•¨ìˆ˜ëª…: snake_case (ì˜ˆ: process_data, create_result)\n"
        guide += "- í´ë˜ìŠ¤ëª…: PascalCase (ì˜ˆ: DataProcessor, ResultHandler)\n"
        guide += "- ìƒìˆ˜ëª…: UPPER_SNAKE_CASE (ì˜ˆ: MAX_RETRY_COUNT)\n"
        guide += "- ë¹„ê³µê°œ ë©¤ë²„: _underscore_prefix\n\n"

        guide += "**í•„ìˆ˜ ê·œì¹™**:\n"
        guide += "- ëª¨ë“  public ë©”ì„œë“œì— íƒ€ì… íŒíŠ¸ í•„ìˆ˜\n"
        guide += "- ì˜ˆì™¸ ì²˜ë¦¬: try-except ë¸”ë¡ìœ¼ë¡œ ì•ˆì „ì„± ë³´ì¥\n"
        guide += "- ë¬¸ì„œí™”: docstringìœ¼ë¡œ ëª©ì ê³¼ ë§¤ê°œë³€ìˆ˜ ì„¤ëª…\n"

        if analysis.performance_notes:
            guide += "- ë¹„ë™ê¸° ì²˜ë¦¬: async/await íŒ¨í„´ ì¤€ìˆ˜\n"

        guide += "- í…ŒìŠ¤íŠ¸: ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì— ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±"

        return guide

    def _generate_execution_guide(self, module_name: str, analysis: CodeAnalysis) -> str:
        """ì‹¤í–‰ ë°©ë²• ì„¹ì…˜ ìƒì„±"""
        guide = "**ì„¤ì¹˜**:\n```bash\n"
        guide += "# ê°œë°œ í™˜ê²½ ì„¤ì¹˜\n"
        guide += "pip install -e .\n"
        guide += "# ë˜ëŠ” ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜\n"
        guide += "pip install -r requirements.txt\n```\n\n"

        guide += "**ì‹¤í–‰**:\n```bash\n"

        if analysis.apis:
            guide += "# API ì„œë²„ ì‹¤í–‰\n"
            guide += f"python -m paca.{module_name.lower().replace(' ', '_')}\n\n"

        # ì£¼ìš” í´ë˜ìŠ¤ ì‚¬ìš© ì˜ˆì‹œ
        if analysis.classes:
            main_class = analysis.classes[0]['name']
            guide += f"# {main_class} ì‚¬ìš© ì˜ˆì‹œ\n"
            guide += "python -c \"\n"
            guide += f"from paca.{module_name.lower().replace(' ', '_')} import {main_class}\n"
            guide += f"instance = {main_class}()\n"
            guide += "print(instance)\"\n"
        else:
            guide += f"# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n"
            guide += f"python -c \"import paca.{module_name.lower().replace(' ', '_')}; print('ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ')\"\n"

        guide += "```"

        return guide

    def _generate_test_guide(self, analysis: CodeAnalysis) -> str:
        """í…ŒìŠ¤íŠ¸ ë°©ë²• ì„¹ì…˜ ìƒì„±"""
        guide = "**ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**:\n```bash\n"

        if analysis.tests:
            guide += f"# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n"
            guide += f"pytest tests/ -v\n\n"
            guide += f"# íŠ¹ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸\n"
            test_file = Path(analysis.tests[0]).name
            guide += f"pytest tests/{test_file} -v\n"
        else:
            guide += "pytest tests/test_*.py -v\n"

        guide += "```\n\n"

        guide += "**ì»¤ë²„ë¦¬ì§€ í…ŒìŠ¤íŠ¸**:\n```bash\n"
        guide += "pytest --cov=paca --cov-report=html\n"
        guide += "# ê²°ê³¼ëŠ” htmlcov/index.htmlì—ì„œ í™•ì¸\n```\n\n"

        guide += "**ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**:\n```bash\n"
        if analysis.performance_notes:
            guide += "# ë¹„ë™ê¸° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n"
            guide += "python -m pytest tests/test_performance.py -v\n"
        else:
            guide += "# ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸\n"
            guide += "python -m timeit \"import paca.module; paca.module.main_function()\"\n"
        guide += "```"

        return guide

    def _generate_considerations(self, analysis: CodeAnalysis) -> str:
        """ì¶”ê°€ ê³ ë ¤ì‚¬í•­ ì„¹ì…˜ ìƒì„±"""
        considerations = "**ë³´ì•ˆ**:\n"

        if analysis.apis:
            considerations += "- API ì¸ì¦ ë° ê¶Œí•œ ê²€ì¦ í•„ìˆ˜\n"
            considerations += "- ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° SQL ì¸ì ì…˜ ë°©ì§€\n"
        else:
            considerations += "- ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° íƒ€ì… ì•ˆì „ì„± ë³´ì¥\n"

        considerations += "\n**ì„±ëŠ¥**:\n"

        if analysis.performance_notes:
            considerations += "- ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë™ì‹œì„± í–¥ìƒ\n"
            considerations += "- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬\n"

        if analysis.complexity_score > 0.7:
            considerations += "- ë³µì¡í•œ ëª¨ë“ˆì´ë¯€ë¡œ ìºì‹± ì „ëµ ê³ ë ¤\n"
            considerations += "- ëª¨ë“ˆ ë¶„í•  ë° ì§€ì—° ë¡œë”© ê²€í† \n"
        else:
            considerations += "- ì‘ë‹µ ì‹œê°„ ìµœì í™” (<100ms ëª©í‘œ)\n"

        considerations += "\n**í–¥í›„ ê°œì„ **:\n"
        considerations += "- íƒ€ì… ì²´í¬ ê°•í™” (mypy strict ëª¨ë“œ)\n"

        if not analysis.tests:
            considerations += "- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€ (ëª©í‘œ: 80%+)\n"

        if len(analysis.dependencies) > 10:
            considerations += "- ì˜ì¡´ì„± ìµœì í™” ë° ë²ˆë“¤ í¬ê¸° ê°ì†Œ\n"

        considerations += "- ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ í†µí•©"

        return considerations

    def _format_readme(self, content: Dict[str, str], module_name: str) -> str:
        """README.md ìµœì¢… í¬ë§·íŒ…"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        readme = f"""# {module_name} Module - PACA Python v5

> ìë™ ìƒì„±ëœ ë¬¸ì„œ (ìƒì„±ì‹œê°„: {timestamp})

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

{content['project_overview']}

## ğŸ“ í´ë”/íŒŒì¼ êµ¬ì¡°

```
{content['folder_structure']}
```

## âš™ï¸ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­

{content['functional_requirements']}

## ğŸ› ï¸ ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­

{content['technical_requirements']}

## ğŸš€ ë¼ìš°íŒ… ë° ì§„ì…ì 

{content['routing_entrypoints']}

## ğŸ“‹ ì½”ë“œ í’ˆì§ˆ ê°€ì´ë“œ

{content['code_quality_guide']}

## ğŸƒâ€â™‚ï¸ ì‹¤í–‰ ë°©ë²•

{content['execution_methods']}

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

{content['testing_methods']}

## ğŸ’¡ ì¶”ê°€ ê³ ë ¤ì‚¬í•­

{content['additional_considerations']}

---

> ì´ ë¬¸ì„œëŠ” PACA v5 Python ë³€í™˜ í”„ë¡œì íŠ¸ì˜ ìë™ ë¬¸ì„œí™” ì‹œìŠ¤í…œì— ì˜í•´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
> ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš° `scripts/auto_documentation_system.py`ë¥¼ í†µí•´ ì¬ìƒì„±í•˜ì„¸ìš”.
"""
        return readme

    def _load_templates(self) -> Dict[str, str]:
        """í…œí”Œë¦¿ ë¡œë“œ (í–¥í›„ í™•ì¥ìš©)"""
        return {}


def generate_all_module_readmes(base_path: str = "C:/Users/kk/claude/paca/paca_python"):
    """ëª¨ë“  ëª¨ë“ˆì— ëŒ€í•´ README.md ìƒì„±"""
    generator = AutoDocumentationGenerator()
    base = Path(base_path)

    # paca í•˜ìœ„ ëª¨ë“ˆë“¤ì— ëŒ€í•´ README ìƒì„±
    paca_modules = base / "paca"
    if paca_modules.exists():
        for module_dir in paca_modules.iterdir():
            if module_dir.is_dir() and not module_dir.name.startswith('__'):
                try:
                    print(f"Generating README for {module_dir.name}...")
                    generator.generate_module_readme(str(module_dir))
                    print(f"[OK] {module_dir.name}/README.md created")
                except Exception as e:
                    print(f"[ERROR] Error generating README for {module_dir.name}: {e}")

    # ë£¨íŠ¸ README ìƒì„±
    try:
        print("Generating main README...")
        generator.generate_module_readme(str(base), "PACA Python v5")
        print("[OK] Main README.md created")
    except Exception as e:
        print(f"[ERROR] Error generating main README: {e}")


if __name__ == "__main__":
    generate_all_module_readmes()