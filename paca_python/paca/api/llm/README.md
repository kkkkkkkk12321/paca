# API LLM Module - PACA Python v5

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”
PACA ì‹œìŠ¤í…œì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM) í†µí•© API ëª¨ë“ˆë¡œ, Google Gemini, OpenAI GPT, Anthropic Claude ë“± ë‹¤ì–‘í•œ LLMê³¼ì˜ í†µí•©, API í‚¤ ê´€ë¦¬, ì‘ë‹µ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.

## ğŸ“ í´ë”/íŒŒì¼ êµ¬ì¡°
```
llm/
â”œâ”€â”€ __init__.py              # ëª¨ë“ˆ ì§„ì…ì  ë° í†µí•© API
â”œâ”€â”€ base.py                  # ê¸°ë³¸ LLM ì¸í„°í˜ì´ìŠ¤
â”œâ”€â”€ gemini.py                # Google Gemini API ì—°ë™
â”œâ”€â”€ openai_client.py         # OpenAI GPT API ì—°ë™
â”œâ”€â”€ claude.py                # Anthropic Claude API ì—°ë™
â””â”€â”€ manager.py               # LLM ê´€ë¦¬ì ë° ë¡œë“œ ë°¸ëŸ°ì‹±
```

## âš™ï¸ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­
**ì…ë ¥**: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸, ëª¨ë¸ ì„¤ì •, API í‚¤, ìš”ì²­ ë§¤ê°œë³€ìˆ˜
**ì¶œë ¥**: LLM ì‘ë‹µ í…ìŠ¤íŠ¸, í† í° ì‚¬ìš©ëŸ‰, ì‘ë‹µ ì‹œê°„, ì‹ ë¢°ë„
**í•µì‹¬ ë¡œì§**: API í‚¤ ê²€ì¦ â†’ ëª¨ë¸ ì„ íƒ â†’ ìš”ì²­ ì „ì†¡ â†’ ì‘ë‹µ ì²˜ë¦¬ â†’ ì—ëŸ¬ í•¸ë“¤ë§

## ğŸ› ï¸ ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­
- Python 3.9+ (aiohttp, asyncio, json)
- ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸ (aiohttp)
- API í‚¤ ë³´ì•ˆ ê´€ë¦¬ (í™˜ê²½ ë³€ìˆ˜)
- í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ì œí•œ

## ğŸš€ ë¼ìš°íŒ… ë° ì§„ì…ì 
```python
from paca.api.llm import LLMManager, GeminiClient

# LLM ê´€ë¦¬ì ì´ˆê¸°í™”
manager = LLMManager()
await manager.initialize()

# ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©
gemini = GeminiClient(api_key="your_api_key")
response = await gemini.generate_text(
    prompt="ì•ˆë…•í•˜ì„¸ìš”. PACA v5ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
    max_tokens=1000,
    temperature=0.7
)

# ê´€ë¦¬ìë¥¼ í†µí•œ ì‚¬ìš© (ìë™ ëª¨ë¸ ì„ íƒ)
response = await manager.generate_text(
    prompt="ë³µì¡í•œ ìˆ˜í•™ ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”.",
    preferred_model="gpt-4"
)
```

## ğŸ“‹ ì½”ë“œ í’ˆì§ˆ ê°€ì´ë“œ
- í´ë˜ìŠ¤: PascalCase (LLMManager, GeminiClient)
- API ë©”ì„œë“œ: snake_case (generate_text, get_models)
- ëª¨ë“  API í˜¸ì¶œì— íƒ€ì„ì•„ì›ƒ ì„¤ì • í•„ìˆ˜
- API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œë§Œ ê´€ë¦¬
- í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… í•„ìˆ˜

## ğŸƒâ€â™‚ï¸ ì‹¤í–‰ ë°©ë²•
```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export GEMINI_API_KEYS="your_gemini_api_key"
export OPENAI_API_KEY="your_openai_api_key"

# ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
python -c "
from paca.api.llm import LLMManager
import asyncio

async def test():
    manager = LLMManager()
    models = await manager.get_available_models()
    print(f'ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {models}')

asyncio.run(test())
"
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•
```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
pytest tests/test_api/test_llm/ -v

# í†µí•© í…ŒìŠ¤íŠ¸ (API í‚¤ í•„ìš”)
pytest tests/integration/test_llm_integration.py -v

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
python tests/performance/test_llm_performance.py
```

## ğŸ’¡ ì¶”ê°€ ê³ ë ¤ì‚¬í•­
**ë³´ì•ˆ**: API í‚¤ ì•”í˜¸í™”, ìš”ì²­/ì‘ë‹µ ë¡œê¹… ì‹œ ë¯¼ê° ì •ë³´ ì œê±°
**ì„±ëŠ¥**: ìš”ì²­ ë°°ì¹˜ ì²˜ë¦¬, ì‘ë‹µ ìºì‹±, ì—°ê²° í’€ë§
**í–¥í›„ ê°œì„ **: ìƒˆë¡œìš´ LLM ëª¨ë¸ ì§€ì›, ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ, ë¹„ìš© ìµœì í™”