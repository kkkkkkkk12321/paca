"""
PACA í”„ë¡œë•ì…˜ ë°°í¬ ê²€ì¦ í…ŒìŠ¤íŠ¸
ì‹œìŠ¤í…œ ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸ ë° ë°°í¬ ì¤€ë¹„ë„ ê²€ì¦
"""

import asyncio
import json
import sys
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# PACA ëª¨ë“ˆ ì„í¬íŠ¸
from paca.tools import ReActFramework, PACAToolManager
from paca.tools.tools.web_search import WebSearchTool
from paca.tools.tools.file_manager import FileManagerTool
from paca.feedback import FeedbackStorage, FeedbackCollector, FeedbackAnalyzer
# ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆì´ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ ê²½ìš° ìŠ¤í‚µ
try:
    from paca.monitoring.logger import PACALogger, LogLevel
    from paca.monitoring.dashboard import MonitoringDashboard
    MONITORING_AVAILABLE = True
except ImportError:
    MONITORING_AVAILABLE = False
    PACALogger = None
    LogLevel = None
    MonitoringDashboard = None


class ProductionValidator:
    """í”„ë¡œë•ì…˜ ë°°í¬ ê²€ì¦ê¸°"""

    def __init__(self):
        self.test_results: Dict[str, Dict[str, Any]] = {}
        self.overall_score = 0.0
        self.start_time = datetime.now()

    async def run_validation(self) -> Dict[str, Any]:
        """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
        print("ğŸš€ PACA í”„ë¡œë•ì…˜ ë°°í¬ ê²€ì¦ ì‹œì‘")
        print("=" * 60)

        # 1. í™˜ê²½ ê²€ì¦
        await self._test_environment()

        # 2. í•µì‹¬ ì‹œìŠ¤í…œ ê²€ì¦
        await self._test_core_systems()

        # 3. ë„êµ¬ ì‹œìŠ¤í…œ ê²€ì¦
        await self._test_tool_systems()

        # 4. í”¼ë“œë°± ì‹œìŠ¤í…œ ê²€ì¦
        await self._test_feedback_system()

        # 5. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦
        if MONITORING_AVAILABLE:
            await self._test_monitoring_system()
        else:
            print("\nğŸ“Š 5. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦ (ìŠ¤í‚µ - ëª¨ë“ˆ ì—†ìŒ)")

        # 6. í†µí•© ì‹œìŠ¤í…œ ê²€ì¦
        await self._test_integration()

        # 7. ì„±ëŠ¥ ê²€ì¦
        await self._test_performance()

        # 8. ì•ˆì •ì„± ê²€ì¦
        await self._test_stability()

        # ìµœì¢… ê²°ê³¼ ê³„ì‚°
        self._calculate_final_score()

        return self._generate_report()

    async def _test_environment(self):
        """í™˜ê²½ ê²€ì¦"""
        print("\nğŸ“‹ 1. í™˜ê²½ ê²€ì¦")
        test_name = "environment"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # Python ë²„ì „ í™•ì¸
            import sys
            if sys.version_info >= (3, 8):
                results["tests"].append({"name": "Python ë²„ì „", "status": "PASS", "details": f"Python {sys.version_info.major}.{sys.version_info.minor}"})
            else:
                results["tests"].append({"name": "Python ë²„ì „", "status": "FAIL", "details": f"Python {sys.version_info.major}.{sys.version_info.minor} (3.8+ í•„ìš”)"})
                results["issues"].append("Python 3.8 ì´ìƒ ë²„ì „ì´ í•„ìš”í•©ë‹ˆë‹¤")

            # í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸
            required_modules = [
                "aiohttp", "aiosqlite", "pydantic", "structlog",
                "psutil", "beautifulsoup4", "requests"
            ]

            for module in required_modules:
                try:
                    __import__(module)
                    results["tests"].append({"name": f"ëª¨ë“ˆ {module}", "status": "PASS", "details": "ì„¤ì¹˜ë¨"})
                except ImportError:
                    results["tests"].append({"name": f"ëª¨ë“ˆ {module}", "status": "FAIL", "details": "ë¯¸ì„¤ì¹˜"})
                    results["issues"].append(f"í•„ìˆ˜ ëª¨ë“ˆ {module}ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

            # ì„¤ì • íŒŒì¼ í™•ì¸
            config_files = [
                ".env.production",
                "requirements.txt",
                "Dockerfile",
                "docker-compose.yml"
            ]

            for config_file in config_files:
                if Path(config_file).exists():
                    results["tests"].append({"name": f"ì„¤ì • íŒŒì¼ {config_file}", "status": "PASS", "details": "ì¡´ì¬í•¨"})
                else:
                    results["tests"].append({"name": f"ì„¤ì • íŒŒì¼ {config_file}", "status": "WARN", "details": "ì—†ìŒ"})
                    results["issues"].append(f"ì„¤ì • íŒŒì¼ {config_file}ì´ ì—†ìŠµë‹ˆë‹¤")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            total = len(results["tests"])
            results["score"] = (passed / total) * 100

            print(f"   âœ… í†µê³¼: {passed}/{total} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"í™˜ê²½ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_core_systems(self):
        """í•µì‹¬ ì‹œìŠ¤í…œ ê²€ì¦"""
        print("\nğŸ”§ 2. í•µì‹¬ ì‹œìŠ¤í…œ ê²€ì¦")
        test_name = "core_systems"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # ReAct í”„ë ˆì„ì›Œí¬ í…ŒìŠ¤íŠ¸
            try:
                tool_manager = PACAToolManager()
                react_framework = ReActFramework(tool_manager)
                session = await react_framework.create_session("test_core")

                # ê¸°ë³¸ ì‚¬ê³  ê³¼ì • í…ŒìŠ¤íŠ¸
                think_result = await react_framework.think(session, "ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì¤‘", 0.8)

                if think_result and think_result.content:
                    results["tests"].append({"name": "ReAct í”„ë ˆì„ì›Œí¬", "status": "PASS", "details": "ì •ìƒ ë™ì‘"})
                else:
                    results["tests"].append({"name": "ReAct í”„ë ˆì„ì›Œí¬", "status": "FAIL", "details": "ì‚¬ê³  ê³¼ì • ì‹¤íŒ¨"})
                    results["issues"].append("ReAct í”„ë ˆì„ì›Œí¬ ì‚¬ê³  ê³¼ì •ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

            except Exception as e:
                results["tests"].append({"name": "ReAct í”„ë ˆì„ì›Œí¬", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ReAct í”„ë ˆì„ì›Œí¬ ì˜¤ë¥˜: {str(e)}")

            # ë„êµ¬ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸
            try:
                tool_manager = PACAToolManager()

                # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
                tool_count = len(tool_manager.tools)
                if tool_count >= 0:  # ë„êµ¬ê°€ ì—†ì–´ë„ ì •ìƒ
                    results["tests"].append({"name": "ë„êµ¬ ê´€ë¦¬ì", "status": "PASS", "details": f"{tool_count}ê°œ ë„êµ¬ ë“±ë¡"})
                else:
                    results["tests"].append({"name": "ë„êµ¬ ê´€ë¦¬ì", "status": "FAIL", "details": "ì´ˆê¸°í™” ì‹¤íŒ¨"})
                    results["issues"].append("ë„êµ¬ ê´€ë¦¬ì ì´ˆê¸°í™”ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

            except Exception as e:
                results["tests"].append({"name": "ë„êµ¬ ê´€ë¦¬ì", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ë„êµ¬ ê´€ë¦¬ì ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            total = len(results["tests"])
            results["score"] = (passed / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"í•µì‹¬ ì‹œìŠ¤í…œ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_tool_systems(self):
        """ë„êµ¬ ì‹œìŠ¤í…œ ê²€ì¦"""
        print("\nğŸ› ï¸ 3. ë„êµ¬ ì‹œìŠ¤í…œ ê²€ì¦")
        test_name = "tool_systems"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # ì›¹ ê²€ìƒ‰ ë„êµ¬ í…ŒìŠ¤íŠ¸
            try:
                web_search = WebSearchTool()
                search_result = await web_search.execute(query="Python programming", max_results=1)

                if search_result.success and search_result.result:
                    results["tests"].append({"name": "ì›¹ ê²€ìƒ‰ ë„êµ¬", "status": "PASS", "details": "ê²€ìƒ‰ ì„±ê³µ"})
                else:
                    results["tests"].append({"name": "ì›¹ ê²€ìƒ‰ ë„êµ¬", "status": "WARN", "details": "ê²€ìƒ‰ ì‹¤íŒ¨ (API ì œí•œ ê°€ëŠ¥)"})

            except Exception as e:
                results["tests"].append({"name": "ì›¹ ê²€ìƒ‰ ë„êµ¬", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ì›¹ ê²€ìƒ‰ ë„êµ¬ ì˜¤ë¥˜: {str(e)}")

            # íŒŒì¼ ê´€ë¦¬ ë„êµ¬ í…ŒìŠ¤íŠ¸
            try:
                file_manager = FileManagerTool(sandbox_mode=True)

                # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
                write_result = await file_manager.execute(
                    operation="write",
                    file_path="test_production.txt",
                    content="Production test file"
                )

                if write_result.success:
                    # íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸
                    read_result = await file_manager.execute(
                        operation="read",
                        file_path="test_production.txt"
                    )

                    if read_result.success and "Production test file" in read_result.result:
                        results["tests"].append({"name": "íŒŒì¼ ê´€ë¦¬ ë„êµ¬", "status": "PASS", "details": "ì½ê¸°/ì“°ê¸° ì„±ê³µ"})
                    else:
                        results["tests"].append({"name": "íŒŒì¼ ê´€ë¦¬ ë„êµ¬", "status": "FAIL", "details": "ì½ê¸° ì‹¤íŒ¨"})
                        results["issues"].append("íŒŒì¼ ê´€ë¦¬ ë„êµ¬ ì½ê¸°ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

                    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ
                    await file_manager.execute(operation="delete", file_path="test_production.txt")
                else:
                    results["tests"].append({"name": "íŒŒì¼ ê´€ë¦¬ ë„êµ¬", "status": "FAIL", "details": "ì“°ê¸° ì‹¤íŒ¨"})
                    results["issues"].append("íŒŒì¼ ê´€ë¦¬ ë„êµ¬ ì“°ê¸°ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

            except Exception as e:
                results["tests"].append({"name": "íŒŒì¼ ê´€ë¦¬ ë„êµ¬", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"íŒŒì¼ ê´€ë¦¬ ë„êµ¬ ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            warned = len([t for t in results["tests"] if t["status"] == "WARN"])
            total = len(results["tests"])
            results["score"] = ((passed + warned * 0.5) / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total}, ê²½ê³ : {warned} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"ë„êµ¬ ì‹œìŠ¤í…œ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_feedback_system(self):
        """í”¼ë“œë°± ì‹œìŠ¤í…œ ê²€ì¦"""
        print("\nğŸ“ 4. í”¼ë“œë°± ì‹œìŠ¤í…œ ê²€ì¦")
        test_name = "feedback_system"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # í”¼ë“œë°± ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸
            try:
                storage = FeedbackStorage("test_feedback.db")
                await storage.initialize()

                # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
                from paca.feedback.models import FeedbackModel, FeedbackType

                test_feedback = FeedbackModel(
                    feedback_type=FeedbackType.GENERAL,
                    session_id="test_session",
                    rating=5,
                    text_feedback="í…ŒìŠ¤íŠ¸ í”¼ë“œë°±"
                )

                # ì €ì¥ í…ŒìŠ¤íŠ¸
                save_success = await storage.save_feedback(test_feedback)
                if save_success:
                    # ì¡°íšŒ í…ŒìŠ¤íŠ¸
                    retrieved = await storage.get_feedback(test_feedback.id)
                    if retrieved and retrieved.text_feedback == "í…ŒìŠ¤íŠ¸ í”¼ë“œë°±":
                        results["tests"].append({"name": "í”¼ë“œë°± ì €ì¥ì†Œ", "status": "PASS", "details": "ì €ì¥/ì¡°íšŒ ì„±ê³µ"})
                    else:
                        results["tests"].append({"name": "í”¼ë“œë°± ì €ì¥ì†Œ", "status": "FAIL", "details": "ì¡°íšŒ ì‹¤íŒ¨"})
                        results["issues"].append("í”¼ë“œë°± ì¡°íšŒê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                else:
                    results["tests"].append({"name": "í”¼ë“œë°± ì €ì¥ì†Œ", "status": "FAIL", "details": "ì €ì¥ ì‹¤íŒ¨"})
                    results["issues"].append("í”¼ë“œë°± ì €ì¥ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

                # í…ŒìŠ¤íŠ¸ DB ì •ë¦¬
                Path("test_feedback.db").unlink(missing_ok=True)

            except Exception as e:
                results["tests"].append({"name": "í”¼ë“œë°± ì €ì¥ì†Œ", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"í”¼ë“œë°± ì €ì¥ì†Œ ì˜¤ë¥˜: {str(e)}")

            # í”¼ë“œë°± ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸
            try:
                storage = FeedbackStorage("test_feedback.db")
                await storage.initialize()
                collector = FeedbackCollector(storage)

                # ìë™ í”¼ë“œë°± ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
                test_context = {
                    "session_id": "test_session",
                    "success": False,
                    "error_message": "í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜"
                }

                auto_feedback = await collector.collect_automatic_feedback("test_session", test_context)
                if auto_feedback:
                    results["tests"].append({"name": "í”¼ë“œë°± ìˆ˜ì§‘ê¸°", "status": "PASS", "details": f"{len(auto_feedback)}ê°œ ìë™ í”¼ë“œë°± ìƒì„±"})
                else:
                    results["tests"].append({"name": "í”¼ë“œë°± ìˆ˜ì§‘ê¸°", "status": "WARN", "details": "ìë™ í”¼ë“œë°± ì—†ìŒ"})

                # í…ŒìŠ¤íŠ¸ DB ì •ë¦¬
                Path("test_feedback.db").unlink(missing_ok=True)

            except Exception as e:
                results["tests"].append({"name": "í”¼ë“œë°± ìˆ˜ì§‘ê¸°", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"í”¼ë“œë°± ìˆ˜ì§‘ê¸° ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            warned = len([t for t in results["tests"] if t["status"] == "WARN"])
            total = len(results["tests"])
            results["score"] = ((passed + warned * 0.5) / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total}, ê²½ê³ : {warned} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"í”¼ë“œë°± ì‹œìŠ¤í…œ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_monitoring_system(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦"""
        print("\nğŸ“Š 5. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦")
        test_name = "monitoring_system"
        results = {"tests": [], "score": 0.0, "issues": []}

        if not MONITORING_AVAILABLE:
            results["tests"].append({"name": "ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ", "status": "SKIP", "details": "ëª¨ë“ˆ ì—†ìŒ"})
            results["score"] = 0.0
            self.test_results[test_name] = results
            return

        try:
            # ë¡œê±° í…ŒìŠ¤íŠ¸
            try:
                logger = PACALogger("test_logger", enable_database=False, enable_console=False)
                await logger.start()

                # ë¡œê·¸ ê¸°ë¡ í…ŒìŠ¤íŠ¸
                await logger.info("í…ŒìŠ¤íŠ¸ ë¡œê·¸", component="test")
                results["tests"].append({"name": "êµ¬ì¡°í™” ë¡œê±°", "status": "PASS", "details": "ë¡œê·¸ ê¸°ë¡ ì„±ê³µ"})

                await logger.stop()

            except Exception as e:
                results["tests"].append({"name": "êµ¬ì¡°í™” ë¡œê±°", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"êµ¬ì¡°í™” ë¡œê±° ì˜¤ë¥˜: {str(e)}")

            # ëŒ€ì‹œë³´ë“œ í…ŒìŠ¤íŠ¸
            try:
                logger = PACALogger("dashboard_test", enable_database=False, enable_console=False)
                dashboard = MonitoringDashboard(logger, update_interval=60)

                await dashboard.start()

                # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸
                dashboard_data = await dashboard.get_dashboard_data()
                if dashboard_data and 'timestamp' in dashboard_data:
                    results["tests"].append({"name": "ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", "status": "PASS", "details": "ë°ì´í„° ì¡°íšŒ ì„±ê³µ"})
                else:
                    results["tests"].append({"name": "ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", "status": "FAIL", "details": "ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨"})
                    results["issues"].append("ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

                await dashboard.stop()

            except Exception as e:
                results["tests"].append({"name": "ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            total = len(results["tests"])
            results["score"] = (passed / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_integration(self):
        """í†µí•© ì‹œìŠ¤í…œ ê²€ì¦"""
        print("\nğŸ”— 6. í†µí•© ì‹œìŠ¤í…œ ê²€ì¦")
        test_name = "integration"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
            try:
                # ë„êµ¬ ê´€ë¦¬ì + ReAct í”„ë ˆì„ì›Œí¬ í†µí•©
                tool_manager = PACAToolManager()
                file_tool = FileManagerTool(sandbox_mode=True)
                await tool_manager.register_tool(file_tool)

                react_framework = ReActFramework(tool_manager)
                session = await react_framework.create_session("integration_test")

                # í†µí•© ì•¡ì…˜ í…ŒìŠ¤íŠ¸
                think_result = await react_framework.think(session, "íŒŒì¼ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤", 0.9)
                if think_result.content:
                    # ì•¡ì…˜ ì‹¤í–‰
                    act_result = await react_framework.act(
                        session,
                        "FileManagerTool",
                        operation="write",
                        file_path="integration_test.txt",
                        content="í†µí•© í…ŒìŠ¤íŠ¸ íŒŒì¼"
                    )

                    if act_result.tool_result and act_result.tool_result.success:
                        results["tests"].append({"name": "ì‹œìŠ¤í…œ í†µí•©", "status": "PASS", "details": "ReAct + ë„êµ¬ ì—°ë™ ì„±ê³µ"})

                        # ì •ë¦¬
                        await react_framework.act(
                            session,
                            "FileManagerTool",
                            operation="delete",
                            file_path="integration_test.txt"
                        )
                    else:
                        results["tests"].append({"name": "ì‹œìŠ¤í…œ í†µí•©", "status": "FAIL", "details": "ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨"})
                        results["issues"].append("í†µí•©ëœ ë„êµ¬ ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                else:
                    results["tests"].append({"name": "ì‹œìŠ¤í…œ í†µí•©", "status": "FAIL", "details": "ì‚¬ê³  ê³¼ì • ì‹¤íŒ¨"})
                    results["issues"].append("í†µí•©ëœ ì‚¬ê³  ê³¼ì •ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

            except Exception as e:
                results["tests"].append({"name": "ì‹œìŠ¤í…œ í†µí•©", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ì‹œìŠ¤í…œ í†µí•© ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            total = len(results["tests"])
            results["score"] = (passed / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"í†µí•© ì‹œìŠ¤í…œ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_performance(self):
        """ì„±ëŠ¥ ê²€ì¦"""
        print("\nâš¡ 7. ì„±ëŠ¥ ê²€ì¦")
        test_name = "performance"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # ReAct í”„ë ˆì„ì›Œí¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            try:
                tool_manager = PACAToolManager()
                react_framework = ReActFramework(tool_manager)

                start_time = time.time()
                session = await react_framework.create_session("perf_test")

                # 10ë²ˆì˜ ì‚¬ê³  ê³¼ì • ì‹¤í–‰
                for i in range(10):
                    await react_framework.think(session, f"ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ {i+1}", 0.8)

                end_time = time.time()
                duration = end_time - start_time
                avg_time = duration / 10

                if avg_time < 0.1:  # 100ms ë¯¸ë§Œ
                    results["tests"].append({"name": "ReAct ì„±ëŠ¥", "status": "PASS", "details": f"í‰ê·  {avg_time*1000:.1f}ms"})
                elif avg_time < 0.5:  # 500ms ë¯¸ë§Œ
                    results["tests"].append({"name": "ReAct ì„±ëŠ¥", "status": "WARN", "details": f"í‰ê·  {avg_time*1000:.1f}ms (ë‹¤ì†Œ ëŠë¦¼)"})
                else:
                    results["tests"].append({"name": "ReAct ì„±ëŠ¥", "status": "FAIL", "details": f"í‰ê·  {avg_time*1000:.1f}ms (ë„ˆë¬´ ëŠë¦¼)"})
                    results["issues"].append(f"ReAct ì„±ëŠ¥ì´ ë„ˆë¬´ ëŠë¦½ë‹ˆë‹¤: {avg_time*1000:.1f}ms")

            except Exception as e:
                results["tests"].append({"name": "ReAct ì„±ëŠ¥", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ReAct ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
            try:
                import psutil
                import os

                process = psutil.Process(os.getpid())
                memory_mb = process.memory_info().rss / 1024 / 1024

                if memory_mb < 100:  # 100MB ë¯¸ë§Œ
                    results["tests"].append({"name": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", "status": "PASS", "details": f"{memory_mb:.1f}MB"})
                elif memory_mb < 500:  # 500MB ë¯¸ë§Œ
                    results["tests"].append({"name": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", "status": "WARN", "details": f"{memory_mb:.1f}MB (ë†’ìŒ)"})
                else:
                    results["tests"].append({"name": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", "status": "FAIL", "details": f"{memory_mb:.1f}MB (ê³¼ë‹¤)"})
                    results["issues"].append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ê³¼ë‹¤í•©ë‹ˆë‹¤: {memory_mb:.1f}MB")

            except Exception as e:
                results["tests"].append({"name": "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            warned = len([t for t in results["tests"] if t["status"] == "WARN"])
            total = len(results["tests"])
            results["score"] = ((passed + warned * 0.7) / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total}, ê²½ê³ : {warned} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"ì„±ëŠ¥ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    async def _test_stability(self):
        """ì•ˆì •ì„± ê²€ì¦"""
        print("\nğŸ›¡ï¸ 8. ì•ˆì •ì„± ê²€ì¦")
        test_name = "stability"
        results = {"tests": [], "score": 0.0, "issues": []}

        try:
            # ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            try:
                tool_manager = PACAToolManager()
                file_tool = FileManagerTool(sandbox_mode=True)
                await tool_manager.register_tool(file_tool)

                react_framework = ReActFramework(tool_manager)
                session = await react_framework.create_session("stability_test")

                # ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œë¡œ ì˜¤ë¥˜ ìœ ë°œ
                error_result = await react_framework.act(
                    session,
                    "FileManagerTool",
                    operation="read",
                    file_path="/invalid/path/file.txt"
                )

                # ì˜¤ë¥˜ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if error_result.tool_result and not error_result.tool_result.success:
                    results["tests"].append({"name": "ì˜¤ë¥˜ ì²˜ë¦¬", "status": "PASS", "details": "ì˜¤ë¥˜ ì ì ˆíˆ ì²˜ë¦¬ë¨"})
                else:
                    results["tests"].append({"name": "ì˜¤ë¥˜ ì²˜ë¦¬", "status": "FAIL", "details": "ì˜¤ë¥˜ ì²˜ë¦¬ ë¯¸í¡"})
                    results["issues"].append("ì˜¤ë¥˜ ì²˜ë¦¬ê°€ ì ì ˆí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

            except Exception as e:
                results["tests"].append({"name": "ì˜¤ë¥˜ ì²˜ë¦¬", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

            # ë™ì‹œì„± í…ŒìŠ¤íŠ¸
            try:
                tool_manager = PACAToolManager()
                react_framework = ReActFramework(tool_manager)

                # ë™ì‹œì— ì—¬ëŸ¬ ì„¸ì…˜ ìƒì„±
                tasks = []
                for i in range(5):
                    task = react_framework.create_session(f"concurrent_test_{i}")
                    tasks.append(task)

                sessions = await asyncio.gather(*tasks, return_exceptions=True)

                # ëª¨ë“  ì„¸ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                successful_sessions = sum(1 for s in sessions if not isinstance(s, Exception))

                if successful_sessions == 5:
                    results["tests"].append({"name": "ë™ì‹œì„± ì²˜ë¦¬", "status": "PASS", "details": "5ê°œ ì„¸ì…˜ ë™ì‹œ ìƒì„± ì„±ê³µ"})
                elif successful_sessions >= 3:
                    results["tests"].append({"name": "ë™ì‹œì„± ì²˜ë¦¬", "status": "WARN", "details": f"{successful_sessions}/5 ì„¸ì…˜ ìƒì„± ì„±ê³µ"})
                else:
                    results["tests"].append({"name": "ë™ì‹œì„± ì²˜ë¦¬", "status": "FAIL", "details": f"{successful_sessions}/5 ì„¸ì…˜ë§Œ ì„±ê³µ"})
                    results["issues"].append(f"ë™ì‹œì„± ì²˜ë¦¬ì—ì„œ {5-successful_sessions}ê°œ ì„¸ì…˜ ì‹¤íŒ¨")

            except Exception as e:
                results["tests"].append({"name": "ë™ì‹œì„± ì²˜ë¦¬", "status": "FAIL", "details": str(e)})
                results["issues"].append(f"ë™ì‹œì„± ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

            # ì ìˆ˜ ê³„ì‚°
            passed = len([t for t in results["tests"] if t["status"] == "PASS"])
            warned = len([t for t in results["tests"] if t["status"] == "WARN"])
            total = len(results["tests"])
            results["score"] = ((passed + warned * 0.6) / total) * 100 if total > 0 else 0

            print(f"   âœ… í†µê³¼: {passed}/{total}, ê²½ê³ : {warned} ({results['score']:.1f}%)")

        except Exception as e:
            results["issues"].append(f"ì•ˆì •ì„± ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
            print(f"   âŒ ì˜¤ë¥˜: {str(e)}")

        self.test_results[test_name] = results

    def _calculate_final_score(self):
        """ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        # ê°€ì¤‘ì¹˜ ì ìš©
        weights = {
            "environment": 0.15,
            "core_systems": 0.25,
            "tool_systems": 0.20,
            "feedback_system": 0.10,
            "monitoring_system": 0.10,
            "integration": 0.10,
            "performance": 0.05,
            "stability": 0.05
        }

        total_score = 0.0
        total_weight = 0.0

        for test_name, weight in weights.items():
            if test_name in self.test_results:
                score = self.test_results[test_name]["score"]
                total_score += score * weight
                total_weight += weight

        self.overall_score = total_score / total_weight if total_weight > 0 else 0.0

    def _generate_report(self) -> Dict[str, Any]:
        """ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        end_time = datetime.now()
        duration = (end_time - self.start_time).total_seconds()

        # ì „ì²´ ì´ìŠˆ ìˆ˜ì§‘
        all_issues = []
        for test_results in self.test_results.values():
            all_issues.extend(test_results.get("issues", []))

        # ë°°í¬ ì¤€ë¹„ë„ í‰ê°€
        if self.overall_score >= 90:
            deployment_status = "READY"
            deployment_message = "í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ"
        elif self.overall_score >= 80:
            deployment_status = "CONDITIONALLY_READY"
            deployment_message = "ì¼ë¶€ ìˆ˜ì • í›„ ë°°í¬ ê°€ëŠ¥"
        elif self.overall_score >= 70:
            deployment_status = "NEEDS_IMPROVEMENT"
            deployment_message = "ìƒë‹¹í•œ ê°œì„  í•„ìš”"
        else:
            deployment_status = "NOT_READY"
            deployment_message = "ë°°í¬ ë¶ˆê°€ - ì‹¬ê°í•œ ë¬¸ì œ ì¡´ì¬"

        report = {
            "summary": {
                "overall_score": round(self.overall_score, 1),
                "deployment_status": deployment_status,
                "deployment_message": deployment_message,
                "test_duration_seconds": round(duration, 1),
                "total_tests": sum(len(results["tests"]) for results in self.test_results.values()),
                "total_issues": len(all_issues),
                "timestamp": end_time.isoformat()
            },
            "test_results": self.test_results,
            "all_issues": all_issues,
            "recommendations": self._generate_recommendations()
        }

        return report

    def _generate_recommendations(self) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ì ìˆ˜ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if self.overall_score < 90:
            low_score_tests = [
                name for name, results in self.test_results.items()
                if results["score"] < 80
            ]

            if low_score_tests:
                recommendations.append(f"ë‹¤ìŒ ì˜ì—­ì˜ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(low_score_tests)}")

        # ê³µí†µ ì´ìŠˆ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        all_issues = []
        for test_results in self.test_results.values():
            all_issues.extend(test_results.get("issues", []))

        if "ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤" in str(all_issues):
            recommendations.append("ëˆ„ë½ëœ Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install -r requirements.txt")

        if "ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤" in str(all_issues):
            recommendations.append("ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ê°œë³„ì ìœ¼ë¡œ ë””ë²„ê¹…í•˜ì„¸ìš”")

        if "ëŠë¦½ë‹ˆë‹¤" in str(all_issues):
            recommendations.append("ì„±ëŠ¥ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš” (ìºì‹±, ë¹„ë™ê¸° ì²˜ë¦¬ ë“±)")

        if "ë©”ëª¨ë¦¬" in str(all_issues):
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”")

        # ë°°í¬ ì¤€ë¹„ ê¶Œì¥ì‚¬í•­
        if self.overall_score >= 80:
            recommendations.append("ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œë¥¼ ì„¤ì •í•˜ì—¬ ì‹¤ì‹œê°„ ìƒíƒœë¥¼ ì¶”ì í•˜ì„¸ìš”")
            recommendations.append("ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œì„ êµ¬ì„±í•˜ì—¬ ë¬¸ì œë¥¼ ì‹ ì†íˆ ê°ì§€í•˜ì„¸ìš”")
            recommendations.append("ë°±ì—… ë° ë³µêµ¬ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”")

        return recommendations


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    validator = ProductionValidator()

    try:
        # ê²€ì¦ ì‹¤í–‰
        report = await validator.run_validation()

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ“Š PACA í”„ë¡œë•ì…˜ ë°°í¬ ê²€ì¦ ê²°ê³¼")
        print("=" * 60)

        summary = report["summary"]
        print(f"ğŸ¯ ì „ì²´ ì ìˆ˜: {summary['overall_score']}%")
        print(f"ğŸ“ˆ ë°°í¬ ìƒíƒœ: {summary['deployment_status']}")
        print(f"ğŸ’¬ ìƒíƒœ ë©”ì‹œì§€: {summary['deployment_message']}")
        print(f"â±ï¸ ê²€ì¦ ì‹œê°„: {summary['test_duration_seconds']}ì´ˆ")
        print(f"ğŸ§ª ì´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}ê°œ")
        print(f"âš ï¸ ì´ ì´ìŠˆ: {summary['total_issues']}ê°œ")

        if report["all_issues"]:
            print(f"\nğŸš¨ ë°œê²¬ëœ ì´ìŠˆ:")
            for issue in report["all_issues"]:
                print(f"   â€¢ {issue}")

        if report["recommendations"]:
            print(f"\nğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:")
            for rec in report["recommendations"]:
                print(f"   â€¢ {rec}")

        # ìƒì„¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        report_file = f"production_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ ìƒì„¸ ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_file}")

        # ì„±ê³µ/ì‹¤íŒ¨ ì¢…ë£Œ ì½”ë“œ
        if summary['deployment_status'] in ['READY', 'CONDITIONALLY_READY']:
            print(f"\nâœ… ê²€ì¦ ì™„ë£Œ - ë°°í¬ ê°€ëŠ¥")
            return 0
        else:
            print(f"\nâŒ ê²€ì¦ ì‹¤íŒ¨ - ë°°í¬ ë¶ˆê°€")
            return 1

    except Exception as e:
        print(f"\nğŸ’¥ ê²€ì¦ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return 2


if __name__ == "__main__":
    exit_code = asyncio.run(main())